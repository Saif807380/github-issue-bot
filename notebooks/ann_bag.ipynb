{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Xa4aTCSp2VpU",
    "outputId": "1c707b83-2567-4c8b-ad96-6a342f958227"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "MD653SQS1jWm"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from collections import Counter\n",
    "from torchtext.vocab import Vocab\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch import nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "N1DFwlw-4iTg"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "cFC-HwRr1-d1"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/content/drive/MyDrive/github-issue-bot/saif_processed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "mf9cISm_2hWz",
    "outputId": "42d3b2d7-b74b-4c53-a102-7fbc8285d757"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>issue</th>\n",
       "      <th>label</th>\n",
       "      <th>label_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>append new column neccesary bot append new col...</td>\n",
       "      <td>0</td>\n",
       "      <td>bug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>student currentsemester would show sections st...</td>\n",
       "      <td>0</td>\n",
       "      <td>bug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>duplicate articles toc causes weird behavior t...</td>\n",
       "      <td>0</td>\n",
       "      <td>bug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fix typo collection finder py summary describe...</td>\n",
       "      <td>0</td>\n",
       "      <td>bug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>zimagi dbshell find psql moreover looks even p...</td>\n",
       "      <td>0</td>\n",
       "      <td>bug</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               issue  label label_name\n",
       "0  append new column neccesary bot append new col...      0        bug\n",
       "1  student currentsemester would show sections st...      0        bug\n",
       "2  duplicate articles toc causes weird behavior t...      0        bug\n",
       "3  fix typo collection finder py summary describe...      0        bug\n",
       "4  zimagi dbshell find psql moreover looks even p...      0        bug"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "id": "vqi-UXPX22qX"
   },
   "outputs": [],
   "source": [
    "tokenizer = get_tokenizer('basic_english')\n",
    "counter = Counter()\n",
    "for idx, data in df.iterrows():\n",
    "  counter.update(tokenizer(data[\"issue\"]))\n",
    "vocab = Vocab(counter, min_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "j13g-hJ93Wh-"
   },
   "outputs": [],
   "source": [
    "text_pipeline = lambda x: [vocab[token] for token in tokenizer(x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DYcSmtBO30tp",
    "outputId": "344a8b82-833d-473a-cc63-21f597cfedfa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fix typo collection finder py summary describe change including rationale design decisions fixed minor typo alway always hint include fixes nnn fixing existing issue issue type pick one delete rest bugfix pull request component name write short name module plugin task feature additional information include additional information help people understand change step step reproduction problem helpful related issue paste verbatim command output e g change paste\n",
      "[69, 1461, 633, 7992, 15, 262, 48, 37, 699, 2189, 113, 2137, 343, 675, 1461, 32637, 416, 1684, 156, 188, 2847, 1141, 196, 8, 8, 24, 1291, 52, 257, 569, 1609, 131, 27, 124, 17, 324, 793, 17, 78, 143, 200, 30, 112, 77, 156, 112, 77, 83, 645, 536, 37, 286, 286, 1619, 73, 741, 109, 8, 522, 2260, 115, 145, 11, 125, 37, 522]\n"
     ]
    }
   ],
   "source": [
    "print(df[\"issue\"][3])\n",
    "print(text_pipeline(df[\"issue\"][3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "id": "uNw4OMpK75rI"
   },
   "outputs": [],
   "source": [
    "dataset = df[[\"issue\", \"label\"]].copy(deep=True)\n",
    "dataset[\"issue\"] = dataset[\"issue\"].apply(lambda x: np.str_(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "id": "tU9SK-Kc8esM"
   },
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(dataset, test_size=0.15)\n",
    "train_data, valid_data = train_test_split(train_data, test_size=0.05)\n",
    "train_data.reset_index(inplace=True, drop=True)\n",
    "valid_data.reset_index(inplace=True, drop=True)\n",
    "test_data.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "QWt4x8bw4O4M"
   },
   "outputs": [],
   "source": [
    "def collate_batch(batch):\n",
    "  label_list, text_list, offsets = [], [], [0]\n",
    "  for (_text, _label) in batch:\n",
    "    label_list.append(_label)\n",
    "    processed_text = torch.tensor(text_pipeline(_text), dtype=torch.int64)\n",
    "    text_list.append(processed_text)\n",
    "    offsets.append(processed_text.size(0))\n",
    "  label_list = torch.tensor(label_list, dtype=torch.int64)\n",
    "  offsets = torch.tensor(offsets[:-1]).cumsum(dim=0)\n",
    "  text_list = torch.cat(text_list)\n",
    "  return label_list.to(device), text_list.to(device), offsets.to(device)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "id": "vpwvwl469xOI"
   },
   "outputs": [],
   "source": [
    "class TextClassificationModel(nn.Module):\n",
    "  def __init__(self, vocab_size, embed_dim, num_class):\n",
    "    super(TextClassificationModel, self).__init__()\n",
    "    self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=True)\n",
    "    self.fc = nn.Linear(embed_dim, num_class)\n",
    "    self.init_weights()\n",
    "\n",
    "  def init_weights(self):\n",
    "    initrange = 0.5\n",
    "    self.embedding.weight.data.uniform_(-initrange, initrange)\n",
    "    self.fc.weight.data.uniform_(-initrange, initrange)\n",
    "    self.fc.bias.data.zero_()\n",
    "\n",
    "  def forward(self, text, offsets):\n",
    "    embedded = self.embedding(text, offsets)\n",
    "    return self.fc(embedded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "id": "Fd17Q_rX-oAO"
   },
   "outputs": [],
   "source": [
    "num_class = len(train_data[\"label\"].unique())\n",
    "vocab_size = len(vocab)\n",
    "emsize = 64\n",
    "model = TextClassificationModel(vocab_size, emsize, num_class).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "id": "i2CwcYc6HIOw"
   },
   "outputs": [],
   "source": [
    "def train(dataloader, criterion):\n",
    "  model.train()\n",
    "  total_acc, total_count = 0, 0\n",
    "  log_interval = 50\n",
    "  start_time = time.time()\n",
    "\n",
    "  for idx, (label, text, offsets) in enumerate(dataloader):\n",
    "      \n",
    "    # forward prop\n",
    "    predicted_label = model(text, offsets)\n",
    "\n",
    "    # calculate loss\n",
    "    loss = criterion(predicted_label, label)\n",
    "\n",
    "    # backward propagation\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
    "    optimizer.step()\n",
    "\n",
    "\n",
    "    total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
    "    total_count += label.size(0)\n",
    "\n",
    "\n",
    "    if idx % log_interval == 0 and idx > 0:\n",
    "      elapsed = time.time() - start_time\n",
    "      print('| epoch {:3d} | {:5d}/{:5d} batches '\n",
    "            '| accuracy {:8.3f} | time {:5.3f}'.format(epoch, idx, len(dataloader),\n",
    "                                        total_acc/total_count, elapsed))\n",
    "      total_acc, total_count = 0, 0\n",
    "      start_time = time.time()\n",
    "\n",
    "def evaluate(dataloader, criterion):\n",
    "  model.eval()\n",
    "  total_acc, total_count = 0, 0\n",
    "\n",
    "  # don't calculate backward gradients\n",
    "  with torch.no_grad():\n",
    "    for idx, (label, text, offsets) in enumerate(dataloader):\n",
    "      predicted_label = model(text, offsets)\n",
    "      loss = criterion(predicted_label, label)\n",
    "      total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
    "      total_count += label.size(0)\n",
    "  return total_acc/total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tjCbQDVWILDP",
    "outputId": "c5f644d9-9d43-4de1-b2e8-ac7771b276f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |    50/  247 batches | accuracy    0.717 | time 0.328\n",
      "| epoch   1 |   100/  247 batches | accuracy    0.719 | time 0.333\n",
      "| epoch   1 |   150/  247 batches | accuracy    0.717 | time 0.338\n",
      "| epoch   1 |   200/  247 batches | accuracy    0.716 | time 0.332\n",
      "-----------------------------------------------------------------\n",
      "| end of epoch   1 | time:  1.70s | valid accuracy    0.708 \n",
      "-----------------------------------------------------------------\n",
      "| epoch   2 |    50/  247 batches | accuracy    0.722 | time 0.345\n",
      "| epoch   2 |   100/  247 batches | accuracy    0.732 | time 0.336\n",
      "| epoch   2 |   150/  247 batches | accuracy    0.721 | time 0.291\n",
      "| epoch   2 |   200/  247 batches | accuracy    0.737 | time 0.332\n",
      "-----------------------------------------------------------------\n",
      "| end of epoch   2 | time:  1.70s | valid accuracy    0.711 \n",
      "-----------------------------------------------------------------\n",
      "| epoch   3 |    50/  247 batches | accuracy    0.728 | time 0.336\n",
      "| epoch   3 |   100/  247 batches | accuracy    0.726 | time 0.335\n",
      "| epoch   3 |   150/  247 batches | accuracy    0.749 | time 0.331\n",
      "| epoch   3 |   200/  247 batches | accuracy    0.730 | time 0.348\n",
      "-----------------------------------------------------------------\n",
      "| end of epoch   3 | time:  1.71s | valid accuracy    0.705 \n",
      "-----------------------------------------------------------------\n",
      "| epoch   4 |    50/  247 batches | accuracy    0.744 | time 0.334\n",
      "| epoch   4 |   100/  247 batches | accuracy    0.743 | time 0.313\n",
      "| epoch   4 |   150/  247 batches | accuracy    0.739 | time 0.352\n",
      "| epoch   4 |   200/  247 batches | accuracy    0.733 | time 0.329\n",
      "-----------------------------------------------------------------\n",
      "| end of epoch   4 | time:  1.69s | valid accuracy    0.705 \n",
      "-----------------------------------------------------------------\n",
      "| epoch   5 |    50/  247 batches | accuracy    0.743 | time 0.320\n",
      "| epoch   5 |   100/  247 batches | accuracy    0.733 | time 0.325\n",
      "| epoch   5 |   150/  247 batches | accuracy    0.749 | time 0.322\n",
      "| epoch   5 |   200/  247 batches | accuracy    0.722 | time 0.355\n",
      "-----------------------------------------------------------------\n",
      "| end of epoch   5 | time:  1.69s | valid accuracy    0.705 \n",
      "-----------------------------------------------------------------\n",
      "| epoch   6 |    50/  247 batches | accuracy    0.753 | time 0.319\n",
      "| epoch   6 |   100/  247 batches | accuracy    0.734 | time 0.344\n",
      "| epoch   6 |   150/  247 batches | accuracy    0.728 | time 0.318\n",
      "| epoch   6 |   200/  247 batches | accuracy    0.740 | time 0.315\n",
      "-----------------------------------------------------------------\n",
      "| end of epoch   6 | time:  1.67s | valid accuracy    0.705 \n",
      "-----------------------------------------------------------------\n",
      "| epoch   7 |    50/  247 batches | accuracy    0.744 | time 0.309\n",
      "| epoch   7 |   100/  247 batches | accuracy    0.728 | time 0.313\n",
      "| epoch   7 |   150/  247 batches | accuracy    0.743 | time 0.340\n",
      "| epoch   7 |   200/  247 batches | accuracy    0.738 | time 0.336\n",
      "-----------------------------------------------------------------\n",
      "| end of epoch   7 | time:  1.67s | valid accuracy    0.705 \n",
      "-----------------------------------------------------------------\n",
      "| epoch   8 |    50/  247 batches | accuracy    0.738 | time 0.323\n",
      "| epoch   8 |   100/  247 batches | accuracy    0.754 | time 0.337\n",
      "| epoch   8 |   150/  247 batches | accuracy    0.736 | time 0.312\n",
      "| epoch   8 |   200/  247 batches | accuracy    0.744 | time 0.356\n",
      "-----------------------------------------------------------------\n",
      "| end of epoch   8 | time:  1.67s | valid accuracy    0.705 \n",
      "-----------------------------------------------------------------\n",
      "| epoch   9 |    50/  247 batches | accuracy    0.729 | time 0.329\n",
      "| epoch   9 |   100/  247 batches | accuracy    0.745 | time 0.343\n",
      "| epoch   9 |   150/  247 batches | accuracy    0.733 | time 0.318\n",
      "| epoch   9 |   200/  247 batches | accuracy    0.746 | time 0.327\n",
      "-----------------------------------------------------------------\n",
      "| end of epoch   9 | time:  1.68s | valid accuracy    0.705 \n",
      "-----------------------------------------------------------------\n",
      "| epoch  10 |    50/  247 batches | accuracy    0.744 | time 0.346\n",
      "| epoch  10 |   100/  247 batches | accuracy    0.735 | time 0.328\n",
      "| epoch  10 |   150/  247 batches | accuracy    0.744 | time 0.344\n",
      "| epoch  10 |   200/  247 batches | accuracy    0.732 | time 0.302\n",
      "-----------------------------------------------------------------\n",
      "| end of epoch  10 | time:  1.67s | valid accuracy    0.705 \n",
      "-----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "EPOCHS = 10\n",
    "LR = 1  # learning rate\n",
    "BATCH_SIZE = 64 # batch size for training\n",
    "  \n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=LR)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.1)\n",
    "\n",
    "total_accu = None\n",
    "\n",
    "train_dataloader = DataLoader(train_data.values, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch)\n",
    "valid_dataloader = DataLoader(valid_data.values, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch)\n",
    "test_dataloader = DataLoader(test_data.values, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_batch)\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    train(train_dataloader, criterion)\n",
    "    accu_val = evaluate(valid_dataloader, criterion)\n",
    "    if total_accu is not None and total_accu > accu_val:\n",
    "      scheduler.step()\n",
    "    else:\n",
    "       total_accu = accu_val\n",
    "    print('-' * 65)\n",
    "    print('| end of epoch {:3d} | time: {:5.2f}s | '\n",
    "          'valid accuracy {:8.3f} '.format(epoch,\n",
    "                                           time.time() - epoch_start_time,\n",
    "                                           accu_val))\n",
    "    print('-' * 65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fbPp-kArItR2",
    "outputId": "bb24784c-62bb-450f-f01b-e6976d34f860"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the results of test dataset.\n",
      "test accuracy    71.32\n"
     ]
    }
   ],
   "source": [
    "print('Checking the results of test dataset.')\n",
    "accu_test = evaluate(test_dataloader, criterion)\n",
    "print('test accuracy {:8.2f}'.format(accu_test*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "id": "EpVuGioyJmZI"
   },
   "outputs": [],
   "source": [
    "classes = {}\n",
    "for i in range(6):\n",
    "  classes[i] = df[\"label_name\"][df[\"label\"]==i].unique()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FShH9VJvMcuA",
    "outputId": "e096e32d-a938-4c5b-f9bd-a29d8c803f3b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'bug',\n",
       " 1: 'design',\n",
       " 2: 'documentation',\n",
       " 3: 'feature',\n",
       " 4: 'help',\n",
       " 5: 'question'}"
      ]
     },
     "execution_count": 160,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "id": "rR0J-qOQOBPD"
   },
   "outputs": [],
   "source": [
    "def predict(text, text_pipeline):\n",
    "    with torch.no_grad():\n",
    "        text = torch.tensor(text_pipeline(text))\n",
    "        output = model(text, torch.tensor([0]))\n",
    "        return output.argmax(1).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "id": "hW7g4lENOJdL"
   },
   "outputs": [],
   "source": [
    "model = model.to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "RJsIJvMmON7f",
    "outputId": "9aa4f5c4-230b-44f1-baff-24a4e414b643"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'bug'"
      ]
     },
     "execution_count": 172,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes[predict(\"This is a bug\", text_pipeline)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "id": "jXoTN7cAOlL1"
   },
   "outputs": [],
   "source": [
    "torch.save(model, '/content/drive/MyDrive/github-issue-bot/models/model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I8v28HTTPTZ2"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "ann_bag.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
